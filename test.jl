#=
test:
- Julia version: 1.0.2
- Author: Von Mir
- Date: 2019-03-16
=#
using Pkg
using LinearAlgebra
using Formatting
using StatsBase
using Distributions
using Plots
using BenchmarkTools


function soft_threshholding(q,t,K)
    x = max.(q-t, zeros(K)) - max.(-q - t, zeros(K))
    return x
end

function descent_dir(x, x, 纬)
    return (x - x)*纬
end

function stepsize(系, Ax, x, x, 渭_vec)
    return max.(min.(- (系' * Ax + (abs.(x) - abs.(x))' * 碌_vec) / Ax' * Ax, 1), 0)
end

function stepnum(系, Ax, x, x, 渭_vec)
    return (- (系' * Ax + (abs.(x) - abs.(x))' * 碌_vec))
end

stepdom(Ax) = Ax'*Ax


function own_stela!(x, f, 渭_vec_norm, K, A, 系, 渭_vec, 谓, objval, err, Maxiter)
    for t = 1:Maxiter
        x = soft_threshholding((x' - ))
    end
end

function kernel_stela!(x, f, AtA_diag, 碌_vec_norm, K, A, 系, 碌_vec, objval, error, Maxiter)
    for t = 1:Maxiter
        x = soft_threshholding((x'- f ./ AtA_diag)', 碌_vec_norm', K)
        @inbounds 未x = descent_dir(x, x, 1)#x - x
        @inbounds Ax = A * 未x
        #bla = descent_dir(x, x, 1)

        @inbounds step_num = stepnum(系, Ax, x, x, 渭_vec) #- (系' * Ax + (abs.(x) - abs.(x))' * 碌_vec)
        @inbounds step_denom = stepdom(Ax) #Ax' * Ax
        step_size =  max.(min.(step_num/ step_denom, 1), 0) #stepsize(系, Ax, x, x, 渭_vec)

        @inbounds x[:] +=  未x[:] * step_size #descent_dir(x, x, step_size)
        @inbounds 系[:] += Ax * step_size

        @inbounds f[:] = 系' * A
        @inbounds f = 0.5 * 系' * 系
        @inbounds g = 碌 * norm(x,1)
        @inbounds objval[t+1] = f[1] + g
        #setindex!(objval[:],f[1]+g,t+1)
        @inbounds error[t+1] = norm(abs.(f' - min.( max.((f - x')', -碌*ones(K) ), 碌*ones(K))), Inf)
        #printfmtln(IterationOut, t+1, "N/A", format(objval[t+1], width=7), format(error[t+1], width=7), format(CPU_Time[t+1], precision=7))
        #printfmtln(IterationOut, t+1, format(step_size[1],width = 4), format(objval[t+1], width=7), format(error[t+1], width=7))

        if error[t+1] < 1e-6
            println("Succesfull")
            break
        elseif t == Maxiter
            println("Optimization not possibles with given amount iterations")
        end

    end
end


function stela_lasso(A::Array{Float64,2}, y::Vector{Float64}, 碌::Float64, Maxiter::Int64)
    if 碌 <= 0
        println("must be positive")
        return
    elseif size(A)[1] != size(y)[1]
        println("Number of rows in A must be equal to dimension of y")
        return
    end

    K = size(A)[2]
    @inbounds AtA_diag = sum(A.*A,dims=1)
    碌_vec = 碌*ones(K)
    @inbounds 碌_vec_norm = 碌_vec'./AtA_diag
    x = zeros(K)
    objval = Array{Float64}(zeros(Maxiter+1))
    error = zeros(Maxiter+1)
    @inbounds 系 = A*x - y
    @inbounds f = 系' * A
    @inbounds f = 0.5 * 系' * 系
    @inbounds g = 碌 * norm(x,1)
    setindex!(objval[:],f[1],1)
    @inbounds error[1] = norm(abs.(f' - min.( max.((f - x')', -碌*ones(K) ), 碌*ones(K))),Inf)

    #IterationOut = "{1:9}|{2:10}|{3:15}|{4:15}"
    #printfmtln(IterationOut,"Iteration", "stepsize", "objval", "error")
    #printfmtln(IterationOut, 1, "N/A", format(objval[1], width=7), format(error[1], width=7))
    kernel_stela!(x, f, AtA_diag, 碌_vec_norm, K, A, 系, 碌_vec, objval, error, Maxiter)
    # for t = 1:Maxiter
    #     x = soft_threshholding((x'- f ./ AtA_diag)', 碌_vec_norm', K)
    #     未x = x - x
    #     Ax = A * 未x
    #
    #     step_num = - (系' * Ax + (abs.(x) - abs.(x))' * 碌_vec)
    #     step_denom = Ax' * Ax
    #     step_size = max.(min.(step_num / step_denom, 1), 0)
    #
    #     x += 未x * step_size
    #     系 += Ax * step_size
    #
    #     f = 系' * A
    #     f = 0.5 * 系' * 系
    #     g = 碌 * norm(x,1)
    #     objval[t+1] = f[1] + g
    #     error[t+1] = norm(abs.(f' - min.( max.((f - x')', -碌*ones(K) ), 碌*ones(K))), Inf)
    #     #printfmtln(IterationOut, t+1, "N/A", format(objval[t+1], width=7), format(error[t+1], width=7), format(CPU_Time[t+1], precision=7))
    #     #printfmtln(IterationOut, t+1, format(step_size[1],width = 4), format(objval[t+1], width=7), format(error[t+1], width=7))
    #
    #     if error[t+1] < 1e-6
    #         println("Succesfull")
    #         break
    #     elseif t == Maxiter
    #         println("Optimization not possibles with given amount iterations")
    #     end
    #
    # end
    return objval, x, error
end

N = 40000
K = 3000
A = rand(Normal(0,0.1),N, K)

dens = 0.01
x0 = zeros(K)
x0_pos = sample(collect(1:K), round(Int,K*dens))

for t = 1:round(Int,K*dens)
    x0[x0_pos[t]] = rand(Normal(0,1))
end

sigma = 0.01
v = rand(Normal(0,sigma), N)'
y = (A*x0 + v')

碌 = 0.01*norm((y'*A),Inf)

@benchmark objval , x, err = stela_lasso(A, y, 碌, 100)
println("fertig")
